return(m)
}
data <- x$get()
m <- mean(data, ...)
x$setmean(m)
m
}
getwd()
ls
ls()
makevector(c(1,2,4,5))
makeVector(c(2,4,6,8))
getmean(4)
cachemean(4)
cachemean(2,4,6,8)
cachemean()
cachemean(list(2,4,6,8))
cachemean(numeric(2,4,6,8))
cachemean(c(2,4,6,8))
x <- c(2,4,6,8)
cachemean(x)
ret <- makeVector()
ret
cachemean(ret)
ret <- makeVector(c(2,4,6,8))
cachemean(ret)
cachemean(ret)
?solve()
makeCacheMatrix <- function(x = matrix()) {
m <- matrix()
set <- function(y) {
x <<- y
m <<- matrix()
}
get <- function() x
setinverse <- function(inverse) m <<- inverse
getinvserse <- function() m
list(set = set, get = get,
setinverse = setinverse,
getinverse = getinverse)
}
A <- matrix(c(1,4,7,9),nrow=2,ncol=2,byrow=TRUE)
solve(A)
B <- solve(A)
b
B
solve(B)
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
m <- x$getinverse()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- solve(data)
x$setinverse(m)
m
}
makeCacheMatrix(A)
makeCacheMatrix <- function(x = matrix()) {
m <- matrix()
set <- function(y) {
x <<- y
m <<- matrix()
}
get <- function() x
setinverse <- function(inverse) m <<- inverse
getinverse <- function() m
list(set = set, get = get,
setinverse = setinverse,
getinverse = getinverse)
}
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
m <- x$getinverse()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- solve(data)
x$setinverse(m)
m
}
makeCacheMatrix(A)
X <- makeCacheMatrix(A)
cacheSolve(X)
makeCacheMatrix <- function(x = matrix()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setinverse <- function(inverse) m <<- inverse
getinverse <- function() m
list(set = set, get = get,
setinverse = setinverse,
getinverse = getinverse)
}
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
m <- x$getinverse()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- solve(data)
x$setinverse(m)
m
}
X <- makeCacheMatrix(A)
cacheSolve(X)
B <- matrix(c(4,8,12,16),nrow=2,ncol=2,byrow=TRUE)
cacheSolve(X)
Y <- makeCacheMatrix(B)
cacheSolve(Y)
cacheSolve(X)
cacheSolve(Y)
C <- matrix(c(1,2,3,4,5,6,7,8,9), nrow=3,ncol=3,byrow=TRUE)
Z <- makeCacheMatrix(C)
cacheSolve(Z)
Z
C
solve(C)
C <- matrix(c(2,4,8,3,6,9,5,10,15),nrow=3,ncol=3,byrow=TRUE)
C
solve(C)
C <- matrix(c(1,2,3,0,4,5,1,0,6),nrow=3,ncol=3,byrow=TRUE)
C
Z <- makeCacheMatrix(C)
cacheSolve(Z)
cacheSolve(Y)
cacheSolve(X)
cacheSolve(Z)
+makeCacheMatrix1 <- function(x = matrix()) {  ## Creates special "matrix" (list of functions)
makeCacheMatrix1 <- function(x = matrix()) {  ## Creates special "matrix" (list of functions)
m <- NULL
set <- function(y) {   ## set the value of the matrix
x <<- y
m <<- NULL
}
get <- function() x   ## get the value of the matrix
setsolve <- function(solve) m <<- solve  ##set the value of the inverse matrix
getsolve <- function() m   ## get the value of the inverse matrix
list(set = set, get = get,
setsolve = setsolve,
getsolve = getsolve)  ## returnes a list of functions described above
}
A <- matrix(c(2,4,6,8),nrow=2, ncol=2, byrow=TRUE)
Y <- makeCacheMatrix1(A)
Y
bye
exit
library("xlsx")
?read.xlsx()
getwd()
list.files()
?read.xlsx()
gasdf <- read.xlsx("Ngas.xlsx",rowIndex = 18:23, colIndex = 7:15)
gasdf <- read.xlsx("Ngas.xlsx",sheetIndex = 1, rowIndex = 18:23, colIndex = 7:15)
gasdf
dat <- read.xlsx("Ngas.xlsx",sheetIndex = 1, rowIndex = 18:23, colIndex = 7:15)
sum(dat$Zip*dat$Ext,na.rm=T)
library("XML")
install.packages("XML")
library("XML")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml", "baltrest.xml",method="curl")
?read.xml()
?xmlParse()
restxml <- xmlParse("baltrest.xml")
restxml
?xpathApply()
zip <- xpathApply(restxml,"zipcode",xmlValue)
zip
print(zip)
zip <- xpathApply(restxml,"/row/zipcode",xmlValue)
zip
zip <- xpathApply(restxml,"//row/zipcode",xmlValue)
zip
zip[1]
df <- data.frame(zip)
df
dim(df)
df[,2]
?table()
a <- table(zip)
a
a[names(a) == 21231]
a[names(a) == "21231"]
zip
dim(zip)
?typeof()
typeof(zip)
?sapply()
sapply(zip, zip=="21231")
sapply(zip, expr = zip=="21231")
zip
?unlist()
zipvector <- unlist(zip)
zipvector
a <- table(zipvector)
a[name(a) == "21321"]
a
a[names(a) == "21231"]
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv ", "microdata.csv",method = "curl")
?fread()
library("data.table")
install.packages("data.table")
?fread()
library("data.table")
?fread()
DAT <- fread("microdata.csv", sep = ",", header = TRUE)
DAT
DAT[,mean(pwgtp15),by=SEX]
exit
source("http//bioconductor.org/biocLite.R")
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library("rhdf5")
created = h5CreateFile("example.h5")
created = h5createFile("example.h5")
created
library()
con = url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlcode = readLines(con)
close con
htmlcode
?readLines()
htmlcode[10]
nchar(htmlcode[10])
nchar(htmlcode[20])
nchar(htmlcode[30])
nchar(htmlcode[100])
?read.fwf()
x <- read.fwf(
file=url("http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for"),
skip=4,
widths=c(12, 7,4, 9,4, 9,4, 9,4))
head(x)
?sum()
sum(x[,4])
x[,4]
x <- read.fwf(
file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),
skip=4,
widths=c(12, 7,4, 9,4, 9,4, 9,4))
?url()
?curl()
?getURL()
install.packages("Rcurl")
install.packages("RCurl")
library(RCurl)
?getURL()
x <- read.fwf(
file=getURL("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),
skip=4,
widths=c(12, 7,4, 9,4, 9,4, 9,4))
head(x)
sum(x[,4])
y <- read.fwf(
file=getURL("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),
skip=4,
widths=c(12, 7,4, 9,4, 9,4, 9,4))
y
file=getURL("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
file
z <- read.fwf(file,skip=4,widths=c(12, 7,4, 9,4, 9,4, 9,4))
read.fwf()
?read.fwf()
?read.fwf()
z <- read.fwf(file,skip=4,widths=c(12, 7,4, 9,4, 9,4, 9,4))
z
x
head(x)
?curl()
file <- curl("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
library(curl)
install.packages("curl")
library(curl)
file <- curl("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
z <- read.fwf(file,skip=4,widths=c(12, 7,4, 9,4, 9,4, 9,4))
z
head(z)
sum(z[,4])
z[,4]
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
?download.file()
getwd()
list()
list.files()
download.file(url,"idaho.csv",method="curl")
idahohousing <- read.csv("idaho.csv")
head(idahohousing)
agricultureLogical <- idahohousing$ACR = 3 & idahohousing$AGS = 6
agricultureLogical <- idahohousing$ACR == 3 & idahohousing$AGS == 6
agriculturelogical
agricultureLogical
?which()
which(agricultureLogical)
library(jpeg)
install.package(jpeg)
install.packages("jpeg")
library(jpeg)
url1 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(url1,"jeff.jpg",method="curl")
?readJPEG()
img <- readJPEG("jeff.jpg",native = TRUE)
img
?quantile()
quantile(img,probs = c(0.3,0.8))
url2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
url3 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(url2,"gdp.csv",method = "curl")
download.file(url3,"edu.csv",method = "curl")
gdp_df <- read.csv("gdp.csv")
edu_df <- read.csv("edu.csv")
head(gdp_df)
head(edu_df)
?match()
?merge()
names(gdp_df)
gdp_df$X
names(edu_df)
merged_df <- merge(gdp_df,edu_df,by.x = "X", by.y = "CountryCode")
View(merged_df)
merged_df <- merge(gdp_df,edu_df,by.x = "X", by.y = "CountryCode", all = TRUE)
merged_df <- merge(gdp_df,edu_df,by.x = "X", by.y = "CountryCode")
View(merged_df)
merged_df <- merge(gdp_df,edu_df,by.x = "X", by.y = "CountryCode", all = TRUE)
View(merged_df)
merged_df <- merge(gdp_df,edu_df,by.x = "X", by.y = "CountryCode")
dim(merged_df)
dim(merged_df)[1]
gdp_df
names(gdp_df)
head(gdp_df)
?read.csv()
head(gdp_df,5)
gdp_df <- read.csv("gdp.csv",skip = 5, nrows = 190, stringsAsFactors = F, header = F)
edu_df <- read.csv("edu.csv", stringsAsFactors = F)
merged_df <- merge(gdp_df,edu_df,by.x = "X", by.y = "CountryCode")
colnames(gdp_df) <- c("countryCode","Rank","X.1","countryName","X.3","X.4","X.5","X.6","X.7","X.8")
merged_df <- merge(gdp_df,edu_df,by.x = "countryCode", by.y = "CountryCode")
dim(merged_df)
head(merged_df)
library(plyr)
?arrange()
arrange(merged_df,desc(Rank))
names(merged_data)
names(merged_df)
merged_df$Income.Group
?group_by()
library(plyr)
?group_by()
library(dplyr)
install.packages("dplyr")
library(dplyr)
?group_by()
?summarize()
?summarise()
?group_by()
group_df <- group_by(merged_df,"Income.Group")
group_df
group_df <- group_by(merged_df,merged_df$Income.Group)
group_df <- group_by(merged_df,Income.Group)
group_df
summarize(group_df, Rank = mean(Rank))
?cut()
table(summarize(group_df, Rank = mean(Rank)))
?group_by()
group1_df <- group_by(merged_df,quantile(rank))
?quantile()
group1_df <- group_by(merged_df,quantile(rank,probs=c(0.2,0.4,0.6,0.8,1)))
group1_df <- group_by(merged_df,quantile(rank,probs=c(0.2,0.4,0.6,0.8,1),na.rm = TRUE))
group1_df <- group_by(merged_df,quantile(rank,probs=c(0.2,0.4,0.6,0.8,1),na.rm = TRUE))
?cut()
group1_df <- cut(merged_df,quantile(rank,probs=c(0.2,0.4,0.6,0.8,1)))
merged_df
names(merged_df)
group1_df <- group_by(merged_df,Rank)
summarize(group1_df, Rank = quantile(Rank,probs=c(0.2,0.4,0.6,0.8.1)))
summarize(group1_df, Rank = quantile(Rank,probs=c(0.2,0.4,0.6,0.8,1)))
cut(merged_df$Rank,quantile(merged_df$Rank,seq(0,1,.2)))
table(cut(merged_df$Rank,quantile(merged_df$Rank,seq(0,1,.2))),merged_df$Income.Group)
bye
library(datasets)
data(cars)
with(cars,plot(speed,dist))
library(ggplot)
library(ggplot2)
install.package("ggplot2")
install.packages("ggplot2")
library(ggplot2)
data(mpg)
qplot(disply, hwy, data = mpg)
qplot(displ, hwy, data = mpg)
library(datasets)
with(airquality, plot(Wind, Ozone))
colors()
?devices()
?devices
bye
library(ggplot2)
?qplot()
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
head(BodyWeight)
class(BodyWeight$Diet)
BodyWeight$Diet
?panel.lmline()
?panel.text()
?llines()
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
print(p)
xyplot(Ozone ~ Wind | factor(Month), data = airquality)
xyplot(Ozone ~ Wind | factor(Month), data = airquality)
?trellis.par.set()
?splom()
?print.trellis()
library(datasets)
data(airquality)
?factor()
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
head(qirquality)
head(airquality)
airquality$Month
?ggplot()
g <- ggplot(movies, aes(votes, rating))
print(g)
qplot(votes, rating, data = movies)
?qplot()
?geom_smooth()
?stats_smooth()
?stat_smooth()
qplot(votes, rating, data = movies) + geom_smooth()
exit
?svd()
library(grDevices)
?colorRamp()
colors()
colors(1)
?colors()
library(RColorBrewer)
cols <- brewer.pal(3, "BuGn")
cols
pal <- colorRampPalette(cols)
image(volcano, col = pal(20))
x <- rnorm(1000)
y <- rnorm(1000)
smoothScatter(x,y)
?rgb()
library(colorspace)
list.files()
setwd("RepData_PeerAssessment1")
activity_df <- read.csv("activity.csv")
activity_df$date <- as.Date(activity_df$date, format="%Y-%m-%d")
activity_array <- tapply(activity_df$steps,activity_df$date,FUN=sum)
hist(activity_array,main = "histogram of total steps per day", xlab="total steps/day")
mean(activity_array, na.rm=TRUE)
median(activity_array, na.rm=TRUE)
interval_array <- tapply(activity_df$steps,activity_df$interval,FUN=mean,na.rm=TRUE)
intervals <- as.numeric(names(interval_array))
interval_df = data.frame(interval = intervals, average_steps = interval_array)
ggplot() + geom_line(data = interval_df, aes(x=interval, y=average_steps)) + xlab("Interval") +
ylab("Average steps taken") + ggtitle("Number of steps taken by interval")
interval_df = data.frame(interval = intervals, average_steps = interval_array)
library(ggplot2)
ggplot() + geom_line(data = interval_df, aes(x=interval, y=average_steps)) + xlab("Interval") +
ylab("Average steps taken") + ggtitle("Number of steps taken by interval")
max_interval <- as.numeric(subset(interval_df, average_steps == max(average_steps),select=interval))
na_records <- length(which(is.na(activity_df$steps)))
na_index <- which(is.na(activity_df$steps))
new_df <- activity_df
for (i in 1:na_records) {
new_df[na_index[i],1] <- interval_df[,2][new_df[na_index[i],3] == interval_df[,1]]
}
new_activity_array <- tapply(new_df$steps,new_df$date,FUN=sum)
hist(new_activity_array,main = "histogram of total steps per day", xlab="total steps/day")
mean(new_activity_array)
median(new_activity_array)
head(new_df)
?weekdays()
dim(new_df)
names(new_df)
weekdays(new_df$date)
new_df$dayofweek <- factor(weekdays(new_df$date))
new_df$dayofweek
levels(new_df$dayofweek)[levels(new_df$dayofweek) in ("Monday","Tuesday","Wednesday","Thursday","Friday")] <- "weekday"
levels(new_df$dayofweek)[levels(new_df$dayofweek) in c("Monday","Tuesday","Wednesday","Thursday","Friday")] <- "weekday"
levels(new_df$dayofweek)[levels(new_df$dayofweek) == "Monday"] <- "weekday"
levels(new_df$dayofweek)[levels(new_df$dayofweek) == "Tuesday"] <- "weekday"
levels(new_df$dayofweek)[levels(new_df$dayofweek) == "Wednesday"] <- "weekday"
levels(new_df$dayofweek)[levels(new_df$dayofweek) == "Thursday"] <- "weekday"
levels(new_df$dayofweek)[levels(new_df$dayofweek) == "Friday"] <- "weekday"
levels(new_df$dayofweek)[levels(new_df$dayofweek) == "Saturday"] <- "weekend"
levels(new_df$dayofweek)[levels(new_df$dayofweek) == "Sunday"] <- "weekend"
new_df$dayofweek
dim(new_df)
names(new_df)
?xyplot()
library(lattice)
?xyplot()
new_interval_array <- tapply(new_df$steps,new_df$interval,FUN=mean,na.rm=TRUE)
new_intervals <- as.numeric(names(new_interval_array))
